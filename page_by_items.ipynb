{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reference_sentences import retrieve_reference_dicts\n",
    "from arxiv_num_extraction import get_arxiv_numbers_from_pdf\n",
    "from retrieval import crossencoder_response, bm25_search\n",
    "from paragraph import get_paragraphs\n",
    "import os\n",
    "\n",
    "reference_dicts = retrieve_reference_dicts('new.pdf')\n",
    "arxiv_nums = get_arxiv_numbers_from_pdf('new.pdf')\n",
    "paragraphs = get_paragraphs('new.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(reference_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': ['We employ a residual connection  around each of the two sub-layers, followed by layer normalization .'], '1': ['We employ a residual connection  around each of the two sub-layers, followed by layer normalization .']}\n"
     ]
    }
   ],
   "source": [
    "print(reference_dicts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'1607.06450': ['We employ a residual connection  around each of the two sub-layers, followed by layer normalization .']}, ['11'])\n"
     ]
    }
   ],
   "source": [
    "def create_arxiv_num_sentence_dict(reference_dicts, arxiv_nums, page_num):\n",
    "    reference_dict = reference_dicts[page_num]\n",
    "    key_nums = list(reference_dict.keys())\n",
    "    new_dict = {}\n",
    "    unfound_nums = []\n",
    "    for key_num in key_nums:\n",
    "        int_key = int(key_num) - 1\n",
    "        arxiv_num = arxiv_nums[int_key]\n",
    "        if arxiv_num is None:\n",
    "            unfound_nums.append(key_num)\n",
    "        else:\n",
    "            new_dict[arxiv_num] = reference_dict[key_num]\n",
    "    return new_dict, unfound_nums\n",
    "    \n",
    "\n",
    "d = create_arxiv_num_sentence_dict(reference_dicts, arxiv_nums, 2)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  'We employ a residual connection  around each of the two sub-layers, followed by layer normalization .',\n",
       "  'we have also experimented with convolutional neural networks. in our preliminary experiments, we observed that layer normalization offers a speedup over the baseline model without normalization, but batch normalization outperforms the other methods. with fully connected layers, all the hidden units in a layer tend to make similar contributions to the ﬁnal prediction and re-centering and re- scaling the summed inputs to a layer works well. however, the assumption of similar contributions is no longer true for convolutional neural networks. the large number of the hidden units whose receptive ﬁelds lie near the boundary of the image are rarely turned on and thus have very different statistics from the rest of the hidden units within the same layer. we think further research is needed to make layer normalization work well in convnets.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similarity(arxiv_dict, arxiv_nums, type='bm25'):\n",
    "    out = []\n",
    "    for key in arxiv_dict.keys():\n",
    "        article_path = os.path.join('pdf_save', key + '.pdf')\n",
    "        corpus = get_paragraphs(article_path)\n",
    "        if key == \"9\":\n",
    "            print(corpus)\n",
    "        for sentence in arxiv_dict[key]:\n",
    "            if type == 'bm25':\n",
    "                closest = bm25_search(corpus, sentence)\n",
    "            else:\n",
    "                closest = crossencoder_response(corpus, sentence)\n",
    "            arxiv_num = arxiv_nums.index(key)\n",
    "            out.append((arxiv_num + 1, sentence, closest))\n",
    "\n",
    "    return out\n",
    "\n",
    "find_similarity(d[0], arxiv_nums, type='crossencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references_from_page(reference_dicts, arxiv_nums, page_num=1, type='bm25'):\n",
    "    arxiv_dict, unfound_nums = create_arxiv_num_sentence_dict(reference_dicts, arxiv_nums, page_num)\n",
    "    out = find_similarity(arxiv_dict, arxiv_nums, type=type)\n",
    "    return out, unfound_nums\n",
    "\n",
    "out, unfound_nums = get_references_from_page(reference_dicts, arxiv_nums, 5, type='crossencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8,\n",
       "  'There are many choices of positional encodings, learned and fixed .',\n",
       "  'next we introduce a fully convolutional architecture for se- quence to sequence modeling. instead of relying on rnns to compute intermediate encoder states zand decoder states hwe use convolutional neural networks (cnn). 3.1. position embeddings'),\n",
       " (8,\n",
       "  'We also experimented with using learned positional embeddings  instead, and found that the two versions produced nearly identical results (see Table 3 row (E)).',\n",
       "  'next we introduce a fully convolutional architecture for se- quence to sequence modeling. instead of relying on rnns to compute intermediate encoder states zand decoder states hwe use convolutional neural networks (cnn). 3.1. position embeddings')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12']\n"
     ]
    }
   ],
   "source": [
    "print(unfound_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
